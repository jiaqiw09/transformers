<!--Copyright 2022 The HuggingFace Team. All rights reserved.

Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
the License. You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on
an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the

âš ï¸ Note that this file is in Markdown but contain specific syntax for our doc-builder (similar to MDX) that may not be
rendered properly in your Markdown viewer.

-->

# å•ä¸ªGPUä¸Šé«˜æ•ˆè®­ç»ƒçš„æ–¹æ³•å’Œå·¥å…·

æœ¬æŒ‡å—æ¼”ç¤ºäº†å¯ä»¥ç”¨æ¥å¢åŠ æ¨¡å‹è®­ç»ƒæ•ˆç‡çš„å®ç”¨æŠ€æœ¯ï¼ŒåŒ…æ‹¬ä¼˜åŒ–å†…å­˜åˆ©ç”¨ã€åŠ é€Ÿè®­ç»ƒæˆ–ä¸¤è€…å…¼é¡¾ã€‚å¦‚æœä½ æƒ³äº†è§£è®­ç»ƒè¿‡ç¨‹ä¸­ GPU çš„åˆ©ç”¨æƒ…å†µï¼Œè¯·å…ˆå‚è€ƒ [æ¨¡å‹è®­ç»ƒå‰–æ](model_memory_anatomy) æ¦‚å¿µæŒ‡å—ã€‚æœ¬æŒ‡å—ä¾§é‡äºå®ç”¨æŠ€å·§ã€‚

<Tip>

å¦‚æœæ‚¨å¯ä»¥è®¿é—®å¸¦æœ‰å¤šä¸ª GPU çš„è®¡ç®—æœºï¼Œè¿™äº›æ–¹æ³•ä»ç„¶æœ‰æ•ˆï¼Œå¹¶ä¸”æ‚¨å¯ä»¥åˆ©ç”¨ [å¤š GPU ç« èŠ‚](perf_train_gpu_many) ä¸­è¯¦ç»†ä»‹ç»çš„å…¶ä»–æ–¹æ³•ã€‚

</Tip>

åœ¨è®­ç»ƒå¤§å‹æ¨¡å‹æ—¶ï¼ŒåŒæ—¶åº”è€ƒè™‘ä¸¤ä¸ªæ–¹é¢ï¼š

* æ•°æ®ååé‡/è®­ç»ƒæ—¶é—´
* æ¨¡å‹æ€§èƒ½

æœ€å¤§åŒ–ååé‡ï¼ˆæ ·æœ¬é‡/ç§’ï¼‰æœ‰åŠ©äºé™ä½è®­ç»ƒæˆæœ¬ã€‚é€šå¸¸é€šè¿‡å°½å¯èƒ½å……åˆ†åˆ©ç”¨ GPUæ¥å°†GPU å†…å­˜å¡«å……åˆ°æé™æ¥å®ç°è¿™ä¸€ç‚¹ã€‚å¦‚æœæœŸæœ›çš„æ•°æ®æ‰¹é‡å¤§å°è¶…è¿‡äº† GPU å†…å­˜çš„é™åˆ¶ï¼Œå†…å­˜ä¼˜åŒ–æŠ€æœ¯ï¼ˆä¾‹å¦‚gradient accumulationï¼‰å¯ä»¥è§£å†³æ­¤ç±»é—®é¢˜ã€‚

ç„¶è€Œï¼Œå¦‚æœå†…å­˜å¤§å°è¶³å¤Ÿå®¹çº³æœŸæœ›çš„æ•°æ®æ‰¹é‡å¤§å°ï¼Œå°±æ²¡æœ‰ç†ç”±åº”ç”¨å†…å­˜ä¼˜åŒ–æŠ€æœ¯ï¼Œå› ä¸ºå®ƒä»¬å¯èƒ½ä¼šå‡æ…¢è®­ç»ƒé€Ÿåº¦ã€‚å¯ä»¥ä½¿ç”¨å¤§æ‰¹é‡æ•°æ®ï¼Œå¹¶ä¸ä¸€å®šæ„å‘³ç€åº”è¯¥è¿™æ ·åšã€‚ä½œä¸ºè¶…å‚æ•°è°ƒæ•´çš„ä¸€éƒ¨åˆ†ï¼Œæ‚¨åº”è¯¥ç¡®å®šå“ªç§æ•°æ®æ‰¹é‡å¤§å°èƒ½äº§ç”Ÿæœ€ä½³ç»“æœï¼Œç„¶åç›¸åº”åœ°çš„ä¼˜åŒ–èµ„æºã€‚

æœ¬æŒ‡å—æ¶µç›–çš„æ–¹æ³•å’Œå·¥å…·å¯ä»¥æ ¹æ®å®ƒä»¬å¯¹è®­ç»ƒè¿‡ç¨‹çš„å½±å“è¿›è¡Œåˆ†ç±»ï¼š

| Method/tool                                                | Improves training speed | Optimizes memory utilization |
|:-----------------------------------------------------------|:------------------------|:-----------------------------|
| [Batch size choice](#batch-size-choice)                    | Yes                     | Yes                          |
| [Gradient accumulation](#gradient-accumulation)            | No                      | Yes                          |
| [Gradient checkpointing](#gradient-checkpointing)          | No                      | Yes                          |
| [Mixed precision training](#mixed-precision-training)      | Yes                     | (No)                         |
| [Optimizer choice](#optimizer-choice)                      | Yes                     | Yes                          |
| [Data preloading](#data-preloading)                        | Yes                     | No                           |
| [DeepSpeed Zero](#deepspeed-zero)                          | No                      | Yes                          |
| [torch.compile](#using-torchcompile)                       | Yes                     | No                           |

<Tip>

æ³¨æ„ï¼šåœ¨ä½¿ç”¨æ··åˆç²¾åº¦æ—¶ï¼Œå¯¹äºå°æ¨¡å‹å’Œå¤§æ‰¹é‡æ•°æ®ï¼Œä¼šæœ‰ä¸€äº›å†…å­˜èŠ‚çœï¼Œä½†å¯¹äºå¤§æ¨¡å‹å’Œå°æ‰¹é‡æ•°æ®ï¼Œå†…å­˜ä½¿ç”¨é‡ä¼šæ›´å¤§ã€‚

</Tip>

æ‚¨å¯ä»¥ç»„åˆä½¿ç”¨è¿™äº›æ–¹æ³•ä»¥è·å¾—ç´¯ç§¯æ•ˆæœã€‚æ— è®ºæ‚¨æ˜¯ä½¿ç”¨[`Trainer`]è®­ç»ƒæ¨¡å‹è¿˜æ˜¯åœ¨çº¯PyTorchåŸç”Ÿè®­ç»ƒå¾ªç¯ï¼Œéƒ½å¯ä»¥é…ç½®è¿™äº›ä¼˜åŒ–ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæ‚¨å¯ä»¥ä½¿ç”¨ ğŸ¤— Accelerate é…ç½®è¿™äº›ä¼˜åŒ–æ–¹æ³•ã€‚

å¦‚æœè¿™äº›æ–¹æ³•æ²¡æœ‰å¸¦æ¥è¶³å¤Ÿçš„æ”¶ç›Šï¼Œæ‚¨å¯ä»¥å°è¯•ä»¥ä¸‹é€‰é¡¹ï¼š
* [è€ƒè™‘ä½¿ç”¨å…·æœ‰é«˜æ•ˆé¢„æ„å»ºè½¯ä»¶çš„è‡ªå®šä¹‰Dockerå®¹å™¨](#efficient-software-prebuilds)
* [è€ƒè™‘ä½¿ç”¨æ··åˆä¸“å®¶ï¼ˆMoEï¼‰æ¨¡å‹](#mixture-of-experts)
* [å°†æ‚¨çš„æ¨¡å‹è½¬æ¢ä¸ºBetterTransformerä»¥åˆ©ç”¨PyTorch native attention](#using-pytorch-native-attention)

æœ€åï¼Œå³ä½¿æ‰€æœ‰è¿™äº›æ–¹æ³•ä»ç„¶ä¸è¶³ä»¥è§£å†³é—®é¢˜ï¼Œå³ä½¿åœ¨åˆ‡æ¢åˆ°æœåŠ¡å™¨çº§GPUï¼ˆå¦‚A100ï¼‰åï¼Œä¹Ÿå¯ä»¥è€ƒè™‘è¿ç§»åˆ°å¤šGPUè®¾ç½®ã€‚è¿™äº›æ–¹æ³•åœ¨å¤šGPUè®¾ç½®ä¸­ä»ç„¶æœ‰æ•ˆï¼Œæ­¤å¤–ï¼Œæ‚¨å¯ä»¥åˆ©ç”¨[å¤šGPUç« èŠ‚](perf_train_gpu_many)ä¸­åˆ—å‡ºçš„å…¶ä»–å¹¶è¡ŒæŠ€æœ¯ã€‚

## Batch size é€‰æ‹©

ä¸ºäº†å®ç°æœ€ä½³æ€§èƒ½ï¼Œé¦–å…ˆè¦ç¡®å®šåˆé€‚çš„æ•°æ®æ‰¹é‡å¤§å°ã€‚å»ºè®®ä½¿ç”¨2^Nçš„æ‰¹é‡å¤§å°å’Œè¾“å…¥/è¾“å‡ºç¥ç»å…ƒæ•°é‡ã€‚é€šå¸¸å®ƒæ˜¯8çš„å€æ•°ï¼Œä½†å–å†³äºæ‰€ä½¿ç”¨çš„ç¡¬ä»¶å’Œæ¨¡å‹çš„æ•°æ®ç±»å‹ã€‚

å‚è€ƒNVIDIAå…³äº[è¾“å…¥/è¾“å‡ºç¥ç»å…ƒæ•°é‡](https://docs.nvidia.com/deeplearning/performance/dl-performance-fully-connected/index.html#input-features)å’Œ[æ‰¹é‡å¤§å°](https://docs.nvidia.com/deeplearning/performance/dl-performance-fully-connected/index.html#batch-size)çš„å»ºè®®ï¼Œå¯¹äºæ¶‰åŠGEMMsï¼ˆé€šç”¨çŸ©é˜µä¹˜æ³•ï¼‰çš„å®Œå…¨è¿æ¥å±‚ã€‚

[å¼ é‡æ ¸å¿ƒè¦æ±‚](https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc)æ ¹æ®æ•°æ®ç±»å‹å’Œç¡¬ä»¶å®šä¹‰ä¹˜æ•°ã€‚ä¾‹å¦‚ï¼Œå¯¹äºfp16æ•°æ®ç±»å‹ï¼Œå»ºè®®æ˜¯8çš„å€æ•°ï¼Œè€ŒA100 GPUå»ºè®®ä½¿ç”¨64çš„å€æ•°ã€‚

å¯¹äºè¾ƒå°çš„å‚æ•°ï¼Œè¿˜éœ€è¦è€ƒè™‘[ç»´åº¦é‡åŒ–æ•ˆæœ](https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#dim-quantization)ã€‚è¿™æ˜¯å…¶ä¸­tilingå‘ç”Ÿçš„åœ°æ–¹ï¼Œæ­£ç¡®çš„ä¹˜æ•°å¯ä»¥å¸¦æ¥æ˜¾è‘—çš„é€Ÿåº¦æå‡ã€‚

## Gradient Accumulation

**æ¢¯åº¦ç´¯ç§¯** æ–¹æ³•æ—¨åœ¨é€æ­¥è®¡ç®—æ¢¯åº¦ï¼Œè€Œä¸æ˜¯ä¸€æ¬¡æ€§è®¡ç®—æ•´ä¸ªæ‰¹æ¬¡çš„æ¢¯åº¦ã€‚è¿™ç§æ–¹æ³•æ¶‰åŠé€šè¿‡æ¨¡å‹è¿›è¡Œè¿­ä»£è®¡ç®—å°æ‰¹æ¬¡çš„å‰å‘å’Œåå‘ä¼ æ’­ï¼Œå¹¶åœ¨æ­¤è¿‡ç¨‹ä¸­ç´¯ç§¯æ¢¯åº¦ã€‚ä¸€æ—¦ç´¯ç§¯äº†è¶³å¤Ÿæ•°é‡çš„æ¢¯åº¦ï¼Œä¾¿æ‰§è¡Œæ¨¡å‹çš„ä¼˜åŒ–æ­¥éª¤ã€‚é€šè¿‡ä½¿ç”¨æ¢¯åº¦ç´¯ç§¯ï¼Œå¯ä»¥å°†**æœ‰æ•ˆæ‰¹é‡å¤§å°**å¢åŠ åˆ° GPU å†…å­˜å®¹é‡æ‰€é™åˆ¶çš„èŒƒå›´ä¹‹å¤–ã€‚ä½†æ˜¯ï¼Œéœ€è¦æ³¨æ„çš„æ˜¯æ¢¯åº¦ç´¯ç§¯å¼•å…¥çš„é¢å¤–å‰å‘å’Œåå‘ä¼ é€’å¯èƒ½ä¼šå‡æ…¢è®­ç»ƒè¿‡ç¨‹ã€‚

æ‚¨å¯ä»¥é€šè¿‡å‘ [`TrainingArguments`] æ·»åŠ  `gradient_accumulation_steps` å‚æ•°æ¥å¯ç”¨æ¢¯åº¦ç´¯ç§¯ï¼š

```py
training_args = TrainingArguments(per_device_train_batch_size=1, gradient_accumulation_steps=4, **default_args)
```

åœ¨ä¸Šé¢çš„ä¾‹å­ä¸­ï¼Œä½ çš„æœ‰æ•ˆæ•°æ®æ‰¹é‡å¤§å°æ˜¯ 4ã€‚

æˆ–è€…ï¼Œä½¿ç”¨ ğŸ¤— Accelerate æ¥å®Œå…¨æ§åˆ¶è®­ç»ƒå¾ªç¯ã€‚åœ¨æœ¬æŒ‡å—çš„[åé¢éƒ¨åˆ†](#using-accelerate)æ‰¾åˆ° ğŸ¤— Accelerate ç¤ºä¾‹ã€‚

è™½ç„¶å»ºè®®å°½å¯èƒ½å……åˆ†åˆ©ç”¨ GPUï¼Œä½†å¤§é‡çš„æ¢¯åº¦ç´¯ç§¯æ­¥éª¤å¯èƒ½ä¼šå¯¼è‡´è®­ç»ƒé€Ÿåº¦æ˜æ˜¾æ”¾ç¼“ã€‚è€ƒè™‘ä»¥ä¸‹ç¤ºä¾‹ã€‚å‡è®¾ `per_device_train_batch_size=4`ï¼ˆä¸ä½¿ç”¨æ¢¯åº¦ç´¯ç§¯ï¼‰å·²ç»è¾¾åˆ°äº† GPU çš„é™åˆ¶ã€‚å¦‚æœæ‚¨æƒ³è¦ä½¿ç”¨å¤§å°ä¸º 64 çš„æ‰¹æ¬¡è¿›è¡Œè®­ç»ƒï¼Œä¸è¦å°† `per_device_train_batch_size` è®¾ç½®ä¸º 1ï¼Œä¹Ÿä¸è¦å°† `gradient_accumulation_steps` è®¾ç½®ä¸º 64ã€‚ç›¸åï¼Œä¿æŒ `per_device_train_batch_size=4`ï¼Œå¹¶è®¾ç½® `gradient_accumulation_steps=16`ã€‚è¿™æ ·å¯ä»¥å¾—åˆ°ç›¸åŒçš„æœ‰æ•ˆæ‰¹é‡å¤§å°ï¼ŒåŒæ—¶æ›´å¥½åœ°åˆ©ç”¨å¯ç”¨çš„ GPU èµ„æºã€‚

äº†è§£æ›´å¤šä¿¡æ¯ï¼Œè¯·å‚è€ƒå…³äº [RTX-3090](https://github.com/huggingface/transformers/issues/14608#issuecomment-1004392537) å’Œ [A100](https://github.com/huggingface/transformers/issues/15026#issuecomment-1005033957) çš„æ‰¹é‡å¤§å°å’Œæ¢¯åº¦ç´¯ç§¯åŸºå‡†æ•°æ®ã€‚

## Gradient Checkpointing

å³ä½¿å°†æ‰¹é‡å¤§å°è®¾ç½®ä¸º 1 å¹¶ä½¿ç”¨æ¢¯åº¦ç´¯ç§¯ï¼Œä¸€äº›å¤§æ¨¡å‹ä»å¯èƒ½é¢ä¸´å†…å­˜é—®é¢˜ã€‚è¿™æ˜¯å› ä¸ºè¿˜æœ‰å…¶ä»–ç»„ä»¶ä¹Ÿéœ€è¦å†…å­˜å­˜å‚¨ã€‚

ä¿å­˜å‰å‘ä¼ é€’ä¸­çš„æ‰€æœ‰æ¿€æ´»å€¼ä»¥åœ¨åå‘ä¼ é€’æœŸé—´è®¡ç®—æ¢¯åº¦å¯èƒ½å¯¼è‡´æ˜¾è‘—çš„å†…å­˜å¼€é”€ã€‚å¦ä¸€ç§æ–¹æ³•ä¸ä¿å­˜æ¿€æ´»å€¼ï¼Œå¹¶åœ¨åå‘ä¼ é€’æœŸé—´é‡æ–°è®¡ç®—å®ƒä»¬ï¼Œä½†è¿™æ ·ä¼šå¼•å…¥ç›¸å½“å¤§çš„è®¡ç®—å¼€é”€å¹¶å‡æ…¢è®­ç»ƒè¿‡ç¨‹ã€‚

**æ¢¯åº¦checkpoint** åœ¨è¿™ä¸¤ç§æ–¹æ³•ä¹‹é—´å¯»æ±‚æŠ˜ä¸­ï¼Œé€šè¿‡åœ¨è®¡ç®—å›¾ä¸­é€‰æ‹©æ€§ä¿å­˜æ¿€æ´»å€¼ï¼Œåªéœ€é‡æ–°è®¡ç®—éƒ¨åˆ†æ¿€æ´»å€¼ä»¥è·å¾—æ¢¯åº¦ã€‚è¦æ·±å…¥äº†è§£æ¢¯åº¦checkpointï¼Œè¯·å‚è€ƒ [è¿™ç¯‡ç²¾å½©çš„æ–‡ç« ](https://medium.com/tensorflow/fitting-larger-networks-into-memory-583e3c758ff9)ã€‚

è¦åœ¨ [`Trainer`] ä¸­å¯ç”¨æ¢¯åº¦checkpointï¼Œè¯·å‘ [`TrainingArguments`] ä¼ é€’ç›¸åº”çš„æ ‡å¿—ï¼š

```py
training_args = TrainingArguments(
    per_device_train_batch_size=1, gradient_accumulation_steps=4, gradient_checkpointing=True, **default_args
)
```

æˆ–è€…ï¼Œä½¿ç”¨ ğŸ¤— Accelerate - åœ¨æœ¬æŒ‡å—çš„[åç»­ç« èŠ‚](#using-accelerate)æ‰¾åˆ° ğŸ¤— Accelerate ç¤ºä¾‹ã€‚

<Tip>

è™½ç„¶`gradient checkpointing`å¯èƒ½ä¼šæé«˜å†…å­˜æ•ˆç‡ï¼Œä½†ä¼šä½¿è®­ç»ƒé€Ÿåº¦å¤§çº¦å‡æ…¢ 20%ã€‚

</Tip>

## æ··åˆç²¾åº¦è®­ç»ƒ

**æ··åˆç²¾åº¦è®­ç»ƒ** æ˜¯ä¸€ç§æ—¨åœ¨é€šè¿‡åˆ©ç”¨ä½ç²¾åº¦æ•°å€¼æ ¼å¼å¤„ç†æŸäº›å˜é‡ï¼Œä»è€Œä¼˜åŒ–è®­ç»ƒæ¨¡å‹çš„è®¡ç®—æ•ˆç‡çš„æŠ€æœ¯ã€‚ä¼ ç»Ÿä¸Šï¼Œå¤§å¤šæ•°æ¨¡å‹ä½¿ç”¨ 32 ä½æµ®ç‚¹ç²¾åº¦ï¼ˆfp32 æˆ– float32ï¼‰æ¥è¡¨ç¤ºå’Œå¤„ç†å˜é‡ã€‚ç„¶è€Œï¼Œå¹¶éæ‰€æœ‰å˜é‡éƒ½éœ€è¦è¿™ç§é«˜ç²¾åº¦çº§åˆ«æ‰èƒ½è·å¾—å‡†ç¡®çš„ç»“æœã€‚é€šè¿‡å°†æŸäº›å˜é‡çš„ç²¾åº¦é™ä½åˆ°è¾ƒä½çš„æ•°å€¼æ ¼å¼ï¼Œå¦‚ 16 ä½æµ®ç‚¹ï¼ˆfp16 æˆ– float16ï¼‰ï¼Œæˆ‘ä»¬å¯ä»¥åŠ å¿«è®¡ç®—é€Ÿåº¦ã€‚å› ä¸ºåœ¨è¿™ç§æ–¹æ³•ä¸­ï¼Œä¸€äº›è®¡ç®—æ˜¯åœ¨åŠç²¾åº¦ä¸‹è¿›è¡Œçš„ï¼Œè€Œä¸€äº›ä»ç„¶æ˜¯åœ¨å®Œæ•´ç²¾åº¦ä¸‹è¿›è¡Œçš„ï¼Œæ‰€ä»¥è¿™ç§æ–¹æ³•è¢«ç§°ä¸ºæ··åˆç²¾åº¦è®­ç»ƒã€‚

æœ€å¸¸è§çš„æ··åˆç²¾åº¦è®­ç»ƒæ˜¯ä½¿ç”¨ fp16ï¼ˆfloat16ï¼‰æ•°æ®ç±»å‹ï¼Œä½†æŸäº› GPU æ¶æ„ï¼ˆå¦‚å®‰åŸ¹æ¶æ„ï¼‰æä¾›äº† bf16 å’Œ tf32ï¼ˆCUDA å†…éƒ¨æ•°æ®ç±»å‹ï¼‰æ•°æ®ç±»å‹ã€‚æŸ¥çœ‹ [NVIDIA åšå®¢](https://developer.nvidia.com/blog/accelerating-ai-training-with-tf32-tensor-cores/) äº†è§£è¿™äº›æ•°æ®ç±»å‹ä¹‹é—´çš„åŒºåˆ«ã€‚

### fp16

æ··åˆç²¾åº¦è®­ç»ƒçš„ä¸»è¦ä¼˜åŠ¿æ¥è‡ªåœ¨åŠç²¾åº¦ï¼ˆfp16ï¼‰ä¸‹ä¿å­˜æ¿€æ´»å€¼ã€‚ä½†å°½ç®¡æ¢¯åº¦ä¹Ÿæ˜¯ä»¥åŠç²¾åº¦è®¡ç®—ï¼Œå®ƒä»¬åœ¨ä¼˜åŒ–æ­¥éª¤ä¸­ä¼šè½¬æ¢å›å®Œæ•´ç²¾åº¦ï¼Œå› æ­¤åœ¨è¿™ä¸€æ­¥å¹¶æœªèŠ‚çœå†…å­˜ã€‚æ··åˆç²¾åº¦è®­ç»ƒå¯ä»¥åŠ å¿«è®¡ç®—ï¼Œä½†ä¹Ÿå¯èƒ½å¯¼è‡´ GPU å†…å­˜çš„æ›´å¤šåˆ©ç”¨ï¼Œç‰¹åˆ«æ˜¯å¯¹äºå°æ‰¹é‡å¤§å°ã€‚è¿™æ˜¯å› ä¸ºç°åœ¨æ¨¡å‹åŒæ—¶ä»¥ 16 ä½å’Œ 32 ä½ç²¾åº¦å­˜åœ¨äº GPU ä¸Šï¼ˆGPU ä¸ŠåŸæ¨¡å‹çš„ 1.5 å€ï¼‰ã€‚

è¦å¯ç”¨æ··åˆç²¾åº¦è®­ç»ƒï¼Œè¯·å°† `fp16` æ ‡å¿—è®¾ç½®ä¸º `True`ï¼š

```py
training_args = TrainingArguments(per_device_train_batch_size=4, fp16=True, **default_args)
```

å¦‚æœä½ æ›´å–œæ¬¢ä½¿ç”¨ ğŸ¤— Accelerateï¼Œè¯·åœ¨æœ¬æŒ‡å—çš„[åç»­éƒ¨åˆ†](#using-accelerate)æ‰¾åˆ° ğŸ¤— Accelerate ç¤ºä¾‹ã€‚

### BF16

å¦‚æœæ‚¨æœ‰å®‰åŸ¹æ¶æ„æˆ–æ›´æ–°çš„ç¡¬ä»¶ï¼Œå¯ä»¥åœ¨æ¨¡å‹æ··åˆç²¾åº¦è®­ç»ƒå’Œè¯„ä¼°ä¸­ä½¿ç”¨ bf16ã€‚è™½ç„¶ bf16 çš„ç²¾åº¦æ¯” fp16 æ›´å·®ï¼Œä½†å®ƒå…·æœ‰æ›´å¤§çš„åŠ¨æ€èŒƒå›´ã€‚åœ¨ fp16 ä¸­ï¼Œæ‚¨å¯ä»¥æ‹¥æœ‰çš„æœ€å¤§æ•°æ˜¯ `65535`ï¼Œä»»ä½•è¶…è¿‡è¿™ä¸ªèŒƒå›´çš„æ•°å­—éƒ½ä¼šå¯¼è‡´æº¢å‡ºã€‚è€Œ bf16 æ•°å¯ä»¥è¾¾åˆ° `3.39e+38`(!)ï¼Œè¿™ä¸ fp32 å¤§è‡´ç›¸åŒ - å› ä¸ºä¸¤è€…éƒ½ä½¿ç”¨ 8 ä½æ¥è¡¨ç¤ºæ•°å€¼èŒƒå›´ã€‚

æ‚¨å¯ä»¥é€šè¿‡ä»¥ä¸‹æ–¹å¼åœ¨ ğŸ¤—  Trainer ä¸­å¯ç”¨ BF16ï¼š

```python
training_args = TrainingArguments(bf16=True, **default_args)
```

### TF32

å®‰åŸ¹æ¶æ„ç¡¬ä»¶ä½¿ç”¨äº†ä¸€ç§ç¥å¥‡çš„æ•°æ®ç±»å‹å«åš tf32ã€‚å®ƒå…·æœ‰ä¸ fp32 ç›¸åŒçš„æ•°å€¼èŒƒå›´ï¼ˆ8 ä½ï¼‰ï¼Œä½†ç²¾åº¦ä¸æ˜¯ 23 ä½ï¼Œè€Œæ˜¯åªæœ‰ 10 ä½ï¼ˆä¸ fp16 ç›¸åŒï¼‰ï¼Œæ€»å…±åªä½¿ç”¨äº† 19 ä½ã€‚å®ƒåœ¨è¿™ç§æ„ä¹‰ä¸Šæ˜¯â€œç¥å¥‡çš„â€ï¼Œå› ä¸ºæ‚¨å¯ä»¥ä½¿ç”¨æ­£å¸¸çš„ fp32 è®­ç»ƒå’Œ/æˆ–æ¨ç†ä»£ç ï¼Œå¹¶é€šè¿‡å¯ç”¨ tf32 ï¼Œå¯ä»¥è·å¾—é«˜è¾¾ 3 å€çš„ååé‡æå‡ã€‚ä½ åªéœ€è¦åœ¨ä»£ç ä¸­æ·»åŠ ä»¥ä¸‹å†…å®¹ï¼š

```
import torch
torch.backends.cuda.matmul.allow_tf32 = True
torch.backends.cudnn.allow_tf32 = True
```

CUDA å°†åœ¨å¯èƒ½çš„æƒ…å†µä¸‹è‡ªåŠ¨åˆ‡æ¢åˆ°ä½¿ç”¨ tf32 è€Œä¸æ˜¯ fp32ï¼Œå‡è®¾ä½¿ç”¨çš„ GPU å±äºå®‰åŸ¹æ¶æ„ç³»åˆ—ã€‚

æ ¹æ® [NVIDIA ç ”ç©¶](https://developer.nvidia.com/blog/accelerating-ai-training-with-tf32-tensor-cores/)ï¼Œå¤§å¤šæ•°æœºå™¨å­¦ä¹ è®­ç»ƒè´Ÿè½½åœ¨ tf32 è®­ç»ƒä¸­æ˜¾ç¤ºå‡ºä¸ fp32 ç›¸åŒçš„å¤æ‚åº¦å’Œæ”¶æ•›æ€§ã€‚å¦‚æœæ‚¨å·²ç»åœ¨ä½¿ç”¨ fp16 æˆ– bf16 æ··åˆç²¾åº¦ï¼Œè¿™ä¹Ÿå¯èƒ½æœ‰åŠ©äºååé‡ã€‚

æ‚¨å¯ä»¥åœ¨ ğŸ¤—  Trainer ä¸­å¯ç”¨è¿™ç§æ¨¡å¼ï¼š

```python
TrainingArguments(tf32=True, **default_args)
```

<Tip>

tf32 ä¸èƒ½ç›´æ¥é€šè¿‡ `tensor.to(dtype=torch.tf32)` å¼€æ°¸ï¼Œå› ä¸ºå®ƒæ˜¯ä¸€ä¸ªå†…éƒ¨ CUDA æ•°æ®ç±»å‹ã€‚æ‚¨éœ€è¦ `torch>=1.7` æ‰èƒ½ä½¿ç”¨ tf32 æ•°æ®ç±»å‹ã€‚

</Tip>

å…³äºtf32ä¸å…¶ä»–ç²¾åº¦çš„æ›´å¤šä¿¡æ¯ï¼Œè¯·å‚è€ƒä»¥ä¸‹åŸºå‡†æµ‹è¯•ï¼š
[RTX-3090](https://github.com/huggingface/transformers/issues/14608#issuecomment-1004390803) å’Œ
[A100](https://github.com/huggingface/transformers/issues/15026#issuecomment-1004543189)ã€‚

## Flash Attention 2

ä½ å¯ä»¥é€šè¿‡åœ¨ transformers ä¸­ä½¿ç”¨ Flash Attention 2 æ¥åŠ å¿«è®­ç»ƒååé‡ã€‚æŸ¥çœ‹ [å• GPU ç« èŠ‚](./perf_infer_gpu_one#Flash-Attention-2) ä¸­ç›¸åº”éƒ¨åˆ†ï¼Œäº†è§£å¦‚ä½•åŠ è½½å¸¦æœ‰ Flash Attention 2 æ¨¡å—çš„æ¨¡å‹ã€‚

## Optimizer é€‰æ‹©

ç”¨äºè®­ç»ƒ Transformer æ¨¡å‹æœ€å¸¸ç”¨çš„ä¼˜åŒ–å™¨æ˜¯ Adam æˆ– AdamWï¼ˆå¸¦æœ‰æƒé‡è¡°å‡çš„ Adamï¼‰ã€‚Adam é€šè¿‡å­˜å‚¨å…ˆå‰æ¢¯åº¦çš„æ»šåŠ¨å¹³å‡å€¼å®ç°è‰¯å¥½çš„æ”¶æ•›æ€§ï¼›ä½†æ˜¯ï¼Œå®ƒä¼šå¢åŠ å¤§çº¦ç­‰äºæ¨¡å‹å‚æ•°æ•°é‡çš„é¢å¤–å†…å­˜å ç”¨ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæ‚¨å¯ä»¥ä½¿ç”¨å¦ä¸€ç§ä¼˜åŒ–å™¨ã€‚ä¾‹å¦‚ï¼Œå¦‚æœæ‚¨å·²å®‰è£…äº† [NVIDIA/apex](https://github.com/NVIDIA/apex)ï¼Œ`adamw_apex_fused` å°†ä¸ºä½ æä¾›æ‰€æœ‰æ”¯æŒçš„ AdamW ä¼˜åŒ–å™¨ä¸­æœ€å¿«çš„è®­ç»ƒä½“éªŒã€‚

[`Trainer`] é›†æˆäº†å„ç§ä¼˜åŒ–å™¨ï¼Œå¯ä»¥ç›´æ¥ä½¿ç”¨ï¼š`adamw_hf`ã€`adamw_torch`ã€`adamw_torch_fused`ã€`adamw_apex_fused`ã€`adamw_anyprecision`ã€`adafactor` æˆ– `adamw_bnb_8bit`ã€‚é€šè¿‡ç¬¬ä¸‰æ–¹å®ç°ï¼Œä¹Ÿå¯ä»¥æ’å…¥æ›´å¤šçš„ä¼˜åŒ–å™¨ã€‚

è®©æˆ‘ä»¬æ›´ä»”ç»†åœ°çœ‹çœ‹ä¸¤ç§æ›¿ä»£ AdamW ä¼˜åŒ–å™¨ï¼š
1. `adafactor`ï¼Œå®ƒåœ¨ [`Trainer`] ä¸­å¯ç”¨ã€‚
2. `adamw_bnb_8bit` ä¹Ÿåœ¨ Trainer ä¸­å¯ç”¨ï¼Œä½†ä¸‹é¢æä¾›äº†ç¬¬ä¸‰æ–¹é›†æˆç¤ºä¾‹ã€‚

ä¸¾ä¾‹æ¥è¯´ï¼Œå¯¹äºä¸€ä¸ª 30 äº¿å‚æ•°çš„æ¨¡å‹ï¼Œæ¯”å¦‚ "t5-3b"ï¼š
* æ ‡å‡†çš„ AdamW ä¼˜åŒ–å™¨å°†éœ€è¦ 24GB çš„ GPU å†…å­˜ï¼Œå› ä¸ºå®ƒä¸ºæ¯ä¸ªå‚æ•°ä½¿ç”¨äº† 8 å­—èŠ‚ï¼ˆ8*3 => 24GBï¼‰ã€‚
* Adafactor ä¼˜åŒ–å™¨å°†éœ€è¦è¶…è¿‡ 12GBã€‚å®ƒä¸ºæ¯ä¸ªå‚æ•°ä½¿ç”¨ç•¥å¤šäº 4 å­—èŠ‚ï¼Œæ‰€ä»¥æ˜¯ 4*3ï¼Œå†åŠ ä¸Šä¸€äº›é¢å¤–å†…å­˜ã€‚
* å¦‚æœæ‰€æœ‰ä¼˜åŒ–å™¨çŠ¶æ€éƒ½è¢«é‡åŒ–çš„è¯ï¼Œ8 ä½ BNB é‡åŒ–ä¼˜åŒ–å™¨åªéœ€ä½¿ç”¨ (2*3) 6GBã€‚

### Adafactor

Adafactor ä¸ä¼šä¸ºæƒé‡çŸ©é˜µä¸­çš„æ¯ä¸ªå…ƒç´ å­˜å‚¨æ»šåŠ¨å¹³å‡å€¼ã€‚ç›¸åï¼Œå®ƒä¿ç•™èšåˆä¿¡æ¯ï¼ˆé€è¡Œå’Œé€åˆ—çš„æ»šåŠ¨å¹³å‡å’Œï¼‰ï¼Œå¤§å¹…å‡å°‘äº†å†…å­˜å ç”¨ã€‚ä½†æ˜¯ï¼Œä¸ Adam ç›¸æ¯”ï¼ŒAdafactor åœ¨æŸäº›æƒ…å†µä¸‹å¯èƒ½æ”¶æ•›é€Ÿåº¦è¾ƒæ…¢ã€‚

æ‚¨å¯ä»¥é€šè¿‡åœ¨ [`TrainingArguments`] ä¸­è®¾ç½® `optim="adafactor"` æ¥åˆ‡æ¢åˆ° Adafactorï¼š

```py
training_args = TrainingArguments(per_device_train_batch_size=4, optim="adafactor", **default_args)
```

ç»“åˆå…¶ä»–æ–¹æ³•ï¼ˆæ¢¯åº¦ç´¯ç§¯ã€æ¢¯åº¦checkpointingå’Œæ··åˆç²¾åº¦è®­ç»ƒï¼‰ï¼Œåœ¨ä¿æŒååé‡çš„åŒæ—¶ï¼Œæ‚¨å¯ä»¥çœ‹åˆ°é«˜è¾¾ 3 å€çš„æ”¹è¿›ï¼ç„¶è€Œï¼Œå¦‚å‰æ‰€è¿°ï¼ŒAdafactor çš„æ”¶æ•›é€Ÿåº¦å¯èƒ½ä¸å¦‚ Adamã€‚

### 8-bit Adam

ä¸ Adafactor èšåˆä¼˜åŒ–å™¨çŠ¶æ€ä¸åŒï¼Œ8 ä½ Adam ä¿ç•™å®Œæ•´çŠ¶æ€å¹¶å¯¹å…¶è¿›è¡Œé‡åŒ–ã€‚é‡åŒ–æ„å‘³ç€ä»¥è¾ƒä½çš„ç²¾åº¦å­˜å‚¨çŠ¶æ€ï¼Œå¹¶ä»…åœ¨ä¼˜åŒ–æ—¶å¯¹å…¶è¿›è¡Œåé‡åŒ–ã€‚è¿™ç±»ä¼¼äºæ··åˆç²¾åº¦è®­ç»ƒçš„æ€æƒ³ã€‚

ä½¿ç”¨`adamw_bnb_8bit`ï¼Œ æ‚¨å¯ä»¥ç®€å•çš„åœ¨[`TrainingArguments`]è®¾ç½®`optim="adamw_bnb_8bit"` 

```py
training_args = TrainingArguments(per_device_train_batch_size=4, optim="adamw_bnb_8bit", **default_args)
```

ç„¶è€Œï¼Œæˆ‘ä»¬ä¹Ÿå¯ä»¥ä»¥æ¼”ç¤ºä¸ºç›®ï¼Œä½¿ç”¨ç¬¬ä¸‰æ–¹å®ç°çš„ 8 ä½ä¼˜åŒ–å™¨ï¼Œä»¥äº†è§£å¦‚ä½•è¿›è¡Œé›†æˆã€‚

é¦–å…ˆï¼ŒæŒ‰ç…§ GitHub [repo](https://github.com/TimDettmers/bitsandbytes) ä¸­çš„å®‰è£…æŒ‡å—å®‰è£…å®ç° 8 ä½ Adam ä¼˜åŒ–å™¨çš„ `bitsandbytes` åº“ã€‚

æ¥ä¸‹æ¥éœ€è¦åˆå§‹åŒ–ä¼˜åŒ–å™¨ã€‚è¿™æ¶‰åŠä¸¤ä¸ªæ­¥éª¤ï¼š
* é¦–å…ˆï¼Œå°†æ¨¡å‹çš„å‚æ•°åˆ†ä¸ºä¸¤ç»„ - ä¸€ç»„åº”ç”¨æƒé‡è¡°å‡ï¼Œå¦ä¸€ç»„åˆ™ä¸åº”ç”¨ã€‚é€šå¸¸ï¼Œåç½®å’Œå±‚å½’ä¸€åŒ–å‚æ•°ä¸è¿›è¡Œæƒé‡è¡°å‡ã€‚
* ç„¶åè¿›è¡Œä¸€äº›å‚æ•°è®¾ç½®ï¼Œä»¥ä½¿ç”¨ä¸ä¹‹å‰ä½¿ç”¨çš„ AdamW ä¼˜åŒ–å™¨ç›¸åŒçš„å‚æ•°ã€‚

```py
import bitsandbytes as bnb
from torch import nn
from transformers.trainer_pt_utils import get_parameter_names

training_args = TrainingArguments(per_device_train_batch_size=4, **default_args)

decay_parameters = get_parameter_names(model, [nn.LayerNorm])
decay_parameters = [name for name in decay_parameters if "bias" not in name]
optimizer_grouped_parameters = [
    {
        "params": [p for n, p in model.named_parameters() if n in decay_parameters],
        "weight_decay": training_args.weight_decay,
    },
    {
        "params": [p for n, p in model.named_parameters() if n not in decay_parameters],
        "weight_decay": 0.0,
    },
]

optimizer_kwargs = {
    "betas": (training_args.adam_beta1, training_args.adam_beta2),
    "eps": training_args.adam_epsilon,
}
optimizer_kwargs["lr"] = training_args.learning_rate
adam_bnb_optim = bnb.optim.Adam8bit(
    optimizer_grouped_parameters,
    betas=(training_args.adam_beta1, training_args.adam_beta2),
    eps=training_args.adam_epsilon,
    lr=training_args.learning_rate,
)
```

æœ€åï¼Œå°†è‡ªå®šä¹‰çš„ä¼˜åŒ–å™¨ä½œä¸ºå‚æ•°ä¼ é€’ç»™ `Trainer`ï¼š

```py
trainer = Trainer(model=model, args=training_args, train_dataset=ds, optimizers=(adam_bnb_optim, None))
```

ç»“åˆå…¶ä»–æ–¹æ³•ï¼ˆæ¢¯åº¦ç´¯ç§¯ã€æ¢¯åº¦checkpointingå’Œæ··åˆç²¾åº¦è®­ç»ƒï¼‰ï¼Œæ‚¨å¯ä»¥æœŸæœ›è·å¾—å¤§çº¦ 3 å€çš„å†…å­˜æ”¹è¿›ï¼Œç”šè‡³æ•°æ®ååé‡ä¼šç•¥é«˜äºä½¿ç”¨ Adafactor ã€‚

### multi_tensor

pytorch-nightly å¼•å…¥äº† `torch.optim._multi_tensor`ï¼Œå®ƒåº”è¯¥æ˜¾è‘—åŠ é€Ÿå…·æœ‰å¤§é‡å°ç‰¹å¾å¼ é‡çš„ä¼˜åŒ–å™¨ã€‚å®ƒæœ€ç»ˆåº”è¯¥ä¼šæˆä¸ºé»˜è®¤è®¾ç½®ï¼Œä½†å¦‚æœæ‚¨æƒ³æ›´æ—©å°è¯•ï¼Œå¯ä»¥æŸ¥çœ‹è¿™ä¸ª GitHub [issue](https://github.com/huggingface/transformers/issues/9965)ã€‚


## æ•°æ®é¢„åŠ è½½

è¾¾åˆ°è‰¯å¥½çš„è®­ç»ƒé€Ÿåº¦çš„ä¸€ä¸ªé‡è¦è¦æ±‚æ˜¯èƒ½å¤Ÿä»¥ GPU èƒ½å¤Ÿå¤„ç†çš„æœ€å¤§é€Ÿåº¦æä¾›æ•°æ®ã€‚é»˜è®¤æƒ…å†µä¸‹ï¼Œæ‰€æœ‰æ“ä½œéƒ½å‘ç”Ÿåœ¨ä¸»è¿›ç¨‹ä¸­ï¼Œè¿™å¯èƒ½æ— æ³•ä»ç£ç›˜å¿«é€Ÿè¯»å–æ•°æ®ï¼Œä»è€Œé€ æˆç“¶é¢ˆï¼Œå¯¼è‡´ GPU åˆ©ç”¨ä¸å……åˆ†ã€‚å¯ä»¥é…ç½®ä»¥ä¸‹å‚æ•°ä»¥å‡å°‘ç“¶é¢ˆï¼š

- `DataLoader(pin_memory=True, ...)` - ç¡®ä¿æ•°æ®é¢„åŠ è½½åˆ° CPU çš„å›ºå®šå†…å­˜ä¸­ï¼Œé€šå¸¸ä¼šä½¿å¾—ä» CPU åˆ° GPU å†…å­˜çš„ä¼ è¾“é€Ÿåº¦æ›´å¿«ã€‚
- `DataLoader(num_workers=4, ...)` - å¯åŠ¨å¤šä¸ªå·¥ä½œè¿›ç¨‹ä»¥æ›´å¿«åœ°é¢„åŠ è½½æ•°æ®ã€‚åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œè§‚å¯Ÿ GPU åˆ©ç”¨ç‡ç»Ÿè®¡ï¼›å¦‚æœè¿œä½äº 100%ï¼Œå°è¯•å¢åŠ å·¥ä½œè¿›ç¨‹çš„æ•°é‡ã€‚å½“ç„¶ï¼Œé—®é¢˜å¯èƒ½å‡ºåœ¨å…¶ä»–åœ°æ–¹ï¼Œæ‰€ä»¥å¢åŠ å·¥ä½œè¿›ç¨‹å¹¶ä¸ä¸€å®šä¼šå¸¦æ¥æ›´å¥½çš„æ€§èƒ½ã€‚

å½“ä½¿ç”¨ [`Trainer`] æ—¶ï¼Œç›¸åº”çš„ [`TrainingArguments`] åŒ…æ‹¬ï¼š`dataloader_pin_memory`ï¼ˆé»˜è®¤ä¸º `True`ï¼‰ï¼Œä»¥åŠ `dataloader_num_workers`ï¼ˆé»˜è®¤ä¸º `0`ï¼‰ã€‚


## DeepSpeed ZeRO

DeepSpeed æ˜¯ä¸€ä¸ªä¸ ğŸ¤— Transformers å’Œ ğŸ¤— Accelerate é›†æˆçš„å¼€æºæ·±åº¦å­¦ä¹ ä¼˜åŒ–åº“ã€‚å®ƒæä¾›äº†å¹¿æ³›çš„åŠŸèƒ½å’Œä¼˜åŒ–ï¼Œæ—¨åœ¨æ”¹å–„å¤§è§„æ¨¡æ·±åº¦å­¦ä¹ è®­ç»ƒçš„æ•ˆç‡å’Œå¯æ‰©å±•æ€§ã€‚

å¦‚æœæ‚¨çš„æ¨¡å‹é€‚åˆå•ä¸ª GPUï¼Œå¹¶ä¸”æœ‰è¶³å¤Ÿçš„ç©ºé—´é€‚åº”å°æ‰¹é‡æ•°æ®ï¼Œé‚£ä¹ˆæ‚¨ä¸éœ€è¦ä½¿ç”¨ DeepSpeedï¼Œå› ä¸ºå®ƒåªä¼šå‡æ…¢é€Ÿåº¦ã€‚ç„¶è€Œï¼Œå¦‚æœæ¨¡å‹ä¸èƒ½é€‚é…å•ä¸ª GPU æˆ–è€…ä¸èƒ½å¤„ç†å°æ‰¹é‡æ•°æ®ï¼Œæ‚¨å¯ä»¥åˆ©ç”¨ DeepSpeed ZeRO + CPU Offloadæ¥å¤„ç†ï¼Œå¯¹äºæ›´å¤§çš„æ¨¡å‹å¯ä»¥ä½¿ç”¨NVMe Offload ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæ‚¨éœ€è¦åˆ†åˆ« [å®‰è£…åº“](main_classes/deepspeed#installation)ï¼Œç„¶åæŒ‰ç…§æŒ‡å—åˆ›å»ºé…ç½®æ–‡ä»¶å¹¶å¯åŠ¨ DeepSpeedï¼š

* å¯¹äº DeepSpeed ä¸ [`Trainer`] çš„æ·±åº¦é›†æˆæŒ‡å—ï¼Œè¯·æŸ¥é˜… [ç›¸å…³æ–‡æ¡£](main_classes/deepspeed)ï¼Œç‰¹åˆ«æ˜¯[å•ä¸ª GPU éƒ¨ç½²ç« èŠ‚](main_classes/deepspeed#deployment-with-one-gpu)ã€‚åœ¨`notebook`ä¸­ä½¿ç”¨ DeepSpeed éœ€è¦è¿›è¡Œä¸€äº›è°ƒæ•´ï¼Œè¯·å‚é˜… [ç›¸å…³æŒ‡å—](main_classes/deepspeed#deployment-in-notebooks)ã€‚
* å¦‚æœæ‚¨å¸Œæœ›ä½¿ç”¨ ğŸ¤— Accelerateï¼Œè¯·å‚è€ƒ [ğŸ¤— Accelerate DeepSpeed æŒ‡å—](https://huggingface.co/docs/accelerate/en/usage_guides/deepspeed)ã€‚


## ä½¿ç”¨ torch.compile

PyTorch 2.0 å¼•å…¥äº†ä¸€ä¸ªæ–°çš„ç¼–è¯‘å‡½æ•°ï¼Œä¸éœ€è¦å¯¹ç°æœ‰ PyTorch ä»£ç è¿›è¡Œä»»ä½•ä¿®æ”¹ï¼Œä½†å¯ä»¥é€šè¿‡æ·»åŠ ä¸€è¡Œä»£ç æ¥ä¼˜åŒ–æ‚¨çš„ä»£ç ï¼š`model = torch.compile(model)`ã€‚

å¦‚æœä½¿ç”¨ [`Trainer`]ï¼Œæ‚¨åªéœ€è¦åœ¨ [`TrainingArguments`] ä¸­ä¼ é€’ `torch_compile` é€‰é¡¹ï¼š

```python
training_args = TrainingArguments(torch_compile=True, **default_args)
```

`torch.compile` ä½¿ç”¨ Python çš„frameè¯„ä¼° API ä»ç°æœ‰çš„ PyTorch ç¨‹åºè‡ªåŠ¨åˆ›å»ºå›¾ã€‚åœ¨æ•è·å›¾åï¼Œå¯ä»¥éƒ¨ç½²ä¸åŒçš„åç«¯ä»¥å°†å›¾é™ä½åˆ°ä¼˜åŒ–å¼•æ“ã€‚æ‚¨å¯ä»¥åœ¨ [PyTorch æ–‡æ¡£](https://pytorch.org/get-started/pytorch-2.0/) ä¸­æ‰¾åˆ°æ›´å¤šè¯¦ç»†ä¿¡æ¯å’ŒåŸºå‡†æµ‹è¯•ã€‚

`torch.compile` æœ‰ä¸€ä¸ªä¸æ–­å¢é•¿çš„åç«¯åˆ—è¡¨ï¼Œå¯ä»¥é€šè¿‡è°ƒç”¨ `torchdynamo.list_backends()` æ‰¾åˆ°ï¼Œæ¯ä¸ªåç«¯éƒ½æœ‰å…¶å¯é€‰ä¾èµ–é¡¹ã€‚

é€šè¿‡åœ¨ [`TrainingArguments`] ä¸­ä½¿ç”¨ `torch_compile_backend` æ¥é€‰æ‹©è¦ä½¿ç”¨çš„åç«¯ã€‚ä¸€äº›å¸¸ç”¨çš„åç«¯åŒ…æ‹¬ï¼š

**è°ƒè¯•åç«¯**ï¼š
* `dynamo.optimize("eager")` - ä½¿ç”¨ PyTorch è¿è¡Œæå–çš„ GraphModuleã€‚è¿™åœ¨è°ƒè¯• TorchDynamo é—®é¢˜æ—¶éå¸¸æœ‰ç”¨ã€‚
* `dynamo.optimize("aot_eager")` - ä½¿ç”¨ AotAutograd å¹¶ä¸ç¼–è¯‘ï¼Œå³åªæ˜¯ä½¿ç”¨ PyTorch eager ç”¨äº AotAutograd æå–çš„å‰å‘å’Œåå‘å›¾ã€‚è¿™å¯¹è°ƒè¯•å¾ˆæœ‰ç”¨ï¼Œä½†ä¸å¤ªå¯èƒ½å¸¦æ¥åŠ é€Ÿã€‚

**è®­ç»ƒå’Œæ¨ç†åç«¯**ï¼š
* `dynamo.optimize("inductor")` - ä½¿ç”¨ TorchInductor åç«¯ï¼Œåˆ©ç”¨ codegened Triton kernels çš„ AotAutograd å’Œ cudagraphs è¿›è¡Œä¼˜åŒ– [é˜…è¯»æ›´å¤š](https://dev-discuss.pytorch.org/t/torchinductor-a-pytorch-native-compiler-with-define-by-run-ir-and-symbolic-shapes/747)
* `dynamo.optimize("nvfuser")` -  ä½¿ç”¨ TorchScript çš„ nvFuserã€‚[é˜…è¯»æ›´å¤š](https://dev-discuss.pytorch.org/t/tracing-with-primitives-update-1-nvfuser-and-its-primitives/593)
* `dynamo.optimize("aot_nvfuser")` -  ä½¿ç”¨ AotAutograd çš„ nvFuserã€‚[é˜…è¯»æ›´å¤š](https://dev-discuss.pytorch.org/t/tracing-with-primitives-update-1-nvfuser-and-its-primitives/593)
* `dynamo.optimize("aot_cudagraphs")` - ä½¿ç”¨ AotAutograd çš„ cudagraphsã€‚[é˜…è¯»æ›´å¤š](https://github.com/pytorch/torchdynamo/pull/757)

**ä»…æ¨ç†åç«¯**ï¼š
* `dynamo.optimize("ofi")` - ä½¿ç”¨ Torchscript çš„ optimize_for_inferenceã€‚ [é˜…è¯»æ›´å¤š](https://pytorch.org/docs/stable/generated/torch.jit.optimize_for_inference.html)
* `dynamo.optimize("fx2trt")` - ä½¿ç”¨ NVIDIA TensorRT è¿›è¡Œæ¨ç†ä¼˜åŒ–ã€‚ [é˜…è¯»æ›´å¤š](https://pytorch.org/TensorRT/tutorials/getting_started_with_fx_path.html)
* `dynamo.optimize("onnxrt")` - ä½¿ç”¨ ONNXRT åœ¨ CPU/GPU ä¸Šè¿›è¡Œæ¨ç†ã€‚ [é˜…è¯»æ›´å¤š](https://onnxruntime.ai/)
* `dynamo.optimize("ipex")` - ä½¿ç”¨ IPEX åœ¨ CPU ä¸Šè¿›è¡Œæ¨ç†ã€‚ [é˜…è¯»æ›´å¤š](https://github.com/intel/intel-extension-for-pytorch)

å…³äºå¦‚ä½•åœ¨ ğŸ¤— Transformers ä¸­ä½¿ç”¨ `torch.compile` çš„ç¤ºä¾‹ï¼Œè¯·æŸ¥çœ‹[åšå®¢æ–‡ç« ï¼Œä½¿ç”¨æœ€æ–°çš„ PyTorch 2.0 ç‰¹æ€§å¯¹ BERT æ¨¡å‹è¿›è¡Œæ–‡æœ¬åˆ†ç±»å¾®è°ƒ](https://www.philschmid.de/getting-started-pytorch-2-0-transformers)


## ä½¿ç”¨ ğŸ¤— Accelerate

é€šè¿‡ [ğŸ¤— Accelerate](https://huggingface.co/docs/accelerate/index)ï¼Œæ‚¨å¯ä»¥ä½¿ç”¨ä¸Šè¿°æ–¹æ³•ï¼Œå¹¶å®Œå…¨æŒæ§è®­ç»ƒå¾ªç¯ï¼Œå®è´¨ä¸Šå¯ä»¥ä½¿ç”¨çº¯ PyTorch ç¼–å†™å¾ªç¯ï¼Œåªéœ€è¿›è¡Œå°‘é‡ä¿®æ”¹ã€‚

å‡è®¾æ‚¨å·²ç»å°†ä¸Šè¿°æ–¹æ³•ç»“åˆåˆ° [`TrainingArguments`] ä¸­ï¼Œå¦‚ä¸‹æ‰€ç¤ºï¼š

```py
training_args = TrainingArguments(
    per_device_train_batch_size=1,
    gradient_accumulation_steps=4,
    gradient_checkpointing=True,
    fp16=True,
    **default_args,
)
```

ğŸ¤— Accelerate çš„å®Œæ•´ç¤ºä¾‹è®­ç»ƒå¾ªç¯ä»…æœ‰å°‘é‡ä»£ç è¡Œï¼š

```py
from accelerate import Accelerator
from torch.utils.data.dataloader import DataLoader

dataloader = DataLoader(ds, batch_size=training_args.per_device_train_batch_size)

if training_args.gradient_checkpointing:
    model.gradient_checkpointing_enable()

accelerator = Accelerator(fp16=training_args.fp16)
model, optimizer, dataloader = accelerator.prepare(model, adam_bnb_optim, dataloader)

model.train()
for step, batch in enumerate(dataloader, start=1):
    loss = model(**batch).loss
    loss = loss / training_args.gradient_accumulation_steps
    accelerator.backward(loss)
    if step % training_args.gradient_accumulation_steps == 0:
        optimizer.step()
        optimizer.zero_grad()
```

é¦–å…ˆï¼Œæˆ‘ä»¬å°†æ•°æ®é›†åŒ…è£…åœ¨ [`DataLoader`](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader) ä¸­ã€‚ç„¶åï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡è°ƒç”¨æ¨¡å‹çš„ [`~PreTrainedModel.gradient_checkpointing_enable`] æ–¹æ³•å¯ç”¨æ¢¯åº¦checkpointingã€‚åœ¨åˆå§‹åŒ– [`Accelerator`](https://huggingface.co/docs/accelerate/package_reference/accelerator#accelerate.Accelerator) æ—¶ï¼Œå¯ä»¥æŒ‡å®šæ˜¯å¦è¦ä½¿ç”¨æ··åˆç²¾åº¦è®­ç»ƒï¼Œå®ƒä¼šåœ¨ [`prepare`] è°ƒç”¨ä¸­ä¸ºæˆ‘ä»¬å¤„ç†ã€‚åœ¨ [`prepare`](https://huggingface.co/docs/accelerate/package_reference/accelerator#accelerate.Accelerator.prepare) è°ƒç”¨æœŸé—´ï¼Œå¦‚æœä½¿ç”¨å¤šä¸ª GPUï¼Œæ•°æ®åŠ è½½å™¨ä¹Ÿä¼šåˆ†å¸ƒåˆ°å¤šä¸ªå·¥ä½œè¿›ç¨‹ä¸­ã€‚æˆ‘ä»¬ä½¿ç”¨å…ˆå‰ç¤ºä¾‹ä¸­çš„ç›¸åŒ [8 ä½ä¼˜åŒ–å™¨](#8-bit-adam)ã€‚

æœ€åï¼Œæˆ‘ä»¬å¯ä»¥æ·»åŠ ä¸»è¦çš„è®­ç»ƒå¾ªç¯ã€‚è¯·æ³¨æ„ï¼Œ`backward` è°ƒç”¨ç”± ğŸ¤— Accelerate å¤„ç†ã€‚æˆ‘ä»¬è¿˜å¯ä»¥çœ‹åˆ°æ¢¯åº¦ç´¯ç§¯çš„å·¥ä½œåŸç†ï¼šå½’ä¸€åŒ–æŸå¤±ï¼Œä»¥ä¾¿åœ¨ç´¯ç§¯ç»“æŸæ—¶å¾—åˆ°å¹³å‡å€¼ï¼Œä¸€æ—¦æ­¥æ•°è¶³å¤Ÿï¼Œè¿è¡Œä¼˜åŒ–ã€‚

ä½¿ç”¨ ğŸ¤— Accelerate å®ç°è¿™äº›ä¼˜åŒ–æŠ€æœ¯åªéœ€è¦å°‘é‡ä»£ç è¡Œï¼Œå¸¦æ¥æ›´å¤šçš„è®­ç»ƒå¾ªç¯çµæ´»æ€§ã€‚è¦äº†è§£æ‰€æœ‰åŠŸèƒ½çš„å®Œæ•´æ–‡æ¡£ï¼Œè¯·æŸ¥çœ‹ [Accelerate æ–‡æ¡£](https://huggingface.co/docs/accelerate/index)ã€‚

## é«˜æ•ˆçš„è½¯ä»¶é¢„æ„å»º

PyTorchçš„[pipå’Œcondaç‰ˆæœ¬](https://pytorch.org/get-started/locally/#start-locally)æ˜¯ä½¿ç”¨cudaå·¥å…·åŒ…é¢„å…ˆæ„å»ºçš„ï¼Œè¿™è¶³ä»¥è¿è¡ŒPyTorchï¼Œä½†å¦‚æœéœ€è¦æ„å»ºcudaæ‰©å±•ç¨‹åºåˆ™ä¸å¤Ÿã€‚

æœ‰æ—¶ï¼Œé¢„å…ˆæ„å»ºæŸäº›ç»„ä»¶å¯èƒ½éœ€è¦é¢å¤–çš„å·¥ä½œã€‚ä¾‹å¦‚ï¼Œå¦‚æœæ‚¨ä½¿ç”¨åƒ`apex`è¿™æ ·çš„åº“ï¼Œè¿™äº›åº“å¹¶æ²¡æœ‰é¢„å…ˆç¼–è¯‘ã€‚åœ¨å…¶ä»–æƒ…å†µä¸‹ï¼Œæ‰¾å‡ºå¦‚ä½•ç³»ç»ŸèŒƒå›´å†…å®‰è£…æ­£ç¡®çš„cudaå·¥å…·åŒ…å¯èƒ½ä¼šå¾ˆå¤æ‚ã€‚ä¸ºäº†è§£å†³è¿™äº›æƒ…å†µï¼ŒPyTorchå’ŒNVIDIAå‘å¸ƒäº†ä¸€ä¸ªæ–°ç‰ˆæœ¬çš„NGC Dockerå®¹å™¨ï¼Œè¯¥å®¹å™¨å·²ç»é¢„å…ˆæ„å»ºå¥½ä¸€åˆ‡ã€‚æ‚¨åªéœ€è¦å°†ä½ çš„ç¨‹åºå®‰è£…åœ¨ä¸Šé¢ï¼Œå®ƒå°±èƒ½ç«‹åˆ»è¿è¡Œã€‚

å¦‚æœæ‚¨æƒ³è°ƒæ•´PyTorchæºä»£ç å’Œ/æˆ–åˆ¶ä½œä¸€ä¸ªæ–°çš„å®šåˆ¶æ„å»ºï¼Œè¿™ç§æ–¹æ³•ä¹Ÿå¾ˆæœ‰ç”¨ã€‚è¦æ‰¾åˆ°æ‚¨æƒ³è¦çš„dockeræ˜ åƒç‰ˆæœ¬ï¼Œå¯ä»¥ä»[PyTorchå‘å¸ƒè¯´æ˜](https://docs.nvidia.com/deeplearning/frameworks/pytorch-release-notes/)å¼€å§‹ï¼Œé€‰æ‹©æœ€æ–°çš„æœˆåº¦ç‰ˆæœ¬ã€‚è¿›å…¥æ‰€éœ€ç‰ˆæœ¬çš„å‘å¸ƒè¯´æ˜ï¼Œæ£€æŸ¥ç¯å¢ƒç»„ä»¶æ˜¯å¦æ»¡è¶³æ‚¨çš„éœ€æ±‚ï¼ˆåŒ…æ‹¬NVIDIAé©±åŠ¨è¦æ±‚ï¼‰ï¼Œç„¶ååœ¨è¯¥æ–‡æ¡£çš„é¡¶éƒ¨è½¬åˆ°ç›¸åº”çš„NGCé¡µé¢ã€‚å¦‚æœæ‚¨å¯¹æ­¤æœ‰æ‰€å›°æƒ‘ï¼Œè¿™é‡Œæ˜¯[æ‰€æœ‰PyTorch NGCæ˜ åƒçš„ç´¢å¼•](https://ngc.nvidia.com/catalog/containers/nvidia:pytorch)ã€‚

æ¥ä¸‹æ¥ï¼ŒæŒ‰ç…§è¯´æ˜ä¸‹è½½å¹¶éƒ¨ç½²dockeræ˜ åƒã€‚

## æ··åˆä¸“å®¶æ¨¡å‹

æœ€è¿‘çš„ä¸€äº›è®ºæ–‡æŠ¥å‘Šç§°ï¼Œå°†æ··åˆä¸“å®¶æ¨¡å‹ï¼ˆMoEï¼‰æŠ€æœ¯é›†æˆåˆ°Transformeræ¨¡å‹ä¸­å¯ä»¥å®ç°4-5å€çš„è®­ç»ƒåŠ é€Ÿå’Œæ›´å¿«çš„æ¨ç†é€Ÿåº¦ã€‚

ç”±äºå‘ç°å‚æ•°è¶Šå¤šï¼Œæ€§èƒ½è¶Šå¥½ï¼Œè¿™ç§æŠ€æœ¯å¯ä»¥åœ¨ä¸å¢åŠ è®­ç»ƒæˆæœ¬çš„æƒ…å†µä¸‹å°†å‚æ•°æ•°é‡æé«˜ä¸€ä¸ªæ•°é‡çº§ã€‚

åœ¨è¿™ç§æ–¹æ³•ä¸­ï¼Œæ¯éš”ä¸€ä¸ªå‰é¦ˆç¥ç»ç½‘ç»œï¼ˆFFNï¼‰å±‚éƒ½è¢«MoEå±‚æ›¿ä»£ï¼ŒMoEå±‚ç”±è®¸å¤šexpertsç»„æˆï¼Œå…¶ä¸­åŒ…å«ä¸€ä¸ªé—¨æ§å‡½æ•°ï¼Œæ ¹æ®åºåˆ—ä¸­è¾“å…¥æ ‡è®°çš„ä½ç½®å‡è¡¡åœ°è®­ç»ƒæ¯ä¸ªexpertsã€‚

![MoE Transformer 2x block](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/perf-moe-transformer.png)

(source: [GLAM](https://ai.googleblog.com/2021/12/more-efficient-in-context-learning-with.html))

æ‚¨å¯ä»¥åœ¨æœ¬èŠ‚æœ«å°¾åˆ—å‡ºçš„è®ºæ–‡ä¸­æ‰¾åˆ°è¯¦å°½çš„ç»†èŠ‚å’Œæ¯”è¾ƒè¡¨æ ¼ã€‚

è¿™ç§æ–¹æ³•çš„ä¸»è¦ç¼ºç‚¹æ˜¯å®ƒéœ€è¦æƒŠäººæ•°é‡çš„GPUå†…å­˜ - å‡ ä¹æ¯”å…¶å¯†é›†ç­‰æ•ˆæ¨¡å‹å¤šä¸€ä¸ªæ•°é‡çº§ã€‚æœ‰å„ç§è’¸é¦å’Œæ–¹æ³•è¢«æå‡ºæ¥ä»¥å…‹æœæ›´é«˜çš„å†…å­˜éœ€æ±‚ã€‚

ä¸è¿‡ï¼Œè¿™å…¶ä¸­å­˜åœ¨ç›´æ¥çš„trade-offï¼Œæ‚¨å¯ä»¥ä½¿ç”¨å°‘é‡expertså’Œ2-3å€è¾ƒå°çš„åŸºç¡€æ¨¡å‹ï¼Œè€Œä¸æ˜¯å‡ åæˆ–ä¸Šç™¾åexpertsã€‚è¿™ä¼šä½¿æ¨¡å‹å°5å€ï¼Œå› æ­¤é€‚å½“æé«˜è®­ç»ƒé€Ÿåº¦çš„åŒæ—¶ä¹Ÿä»…ä»…é€‚åº¦å¢åŠ äº†å†…å­˜éœ€æ±‚ã€‚

å¤§å¤šæ•°ç›¸å…³çš„è®ºæ–‡å’Œå®ç°éƒ½æ˜¯å›´ç»•Tensorflow/TPUsæ„å»ºçš„ã€‚

- [GShard: Scaling Giant Models with Conditional Computation and Automatic Sharding](https://arxiv.org/abs/2006.16668)
- [Switch Transformers: Scaling to Trillion Parameter Models with Simple and Efficient Sparsity](https://arxiv.org/abs/2101.03961)
- [GLaM: Generalist Language Model (GLaM)](https://ai.googleblog.com/2021/12/more-efficient-in-context-learning-with.html)

é’ˆå¯¹ PyTorchï¼ŒDeepSpeed ä¹Ÿæ„å»ºäº†ä¸€ä¸ªæ¨¡å‹ï¼š [DeepSpeed-MoE: Advancing Mixture-of-Experts Inference and Training to Power Next-Generation AI Scale](https://arxiv.org/abs/2201.05596), [Mixture of Experts](https://www.deepspeed.ai/tutorials/mixture-of-experts/) - åšå®¢æ–‡ç« :  [1](https://www.microsoft.com/en-us/research/blog/deepspeed-powers-8x-larger-moe-model-training-with-high-performance/), [2](https://www.microsoft.com/en-us/research/publication/scalable-and-efficient-moe-training-for-multitask-multilingual-models/) ä»¥åŠåŸºäºTransformerçš„å¤§å‹è‡ªç„¶è¯­è¨€ç”Ÿæˆæ¨¡å‹çš„ç‰¹å®šéƒ¨ç½²ï¼š [åšå®¢æ–‡ç« ](https://www.deepspeed.ai/2021/12/09/deepspeed-moe-nlg.html), [Megatron-Deepspeed branch](https://github.com/microsoft/Megatron-DeepSpeed/tree/moe-training).

## ä½¿ç”¨ PyTorch åŸç”Ÿ attention å’Œ Flash Attention

PyTorch 2.0å‘å¸ƒäº†ä¸€ä¸ªåŸç”Ÿçš„[`torch.nn.functional.scaled_dot_product_attention`](https://pytorch.org/docs/master/generated/torch.nn.functional.scaled_dot_product_attention.html) (SDPA)ï¼Œå…è®¸ä½¿ç”¨èåˆçš„GPUæ ¸å¿ƒï¼Œä¾‹å¦‚[é«˜æ•ˆä½¿ç”¨å†…å­˜çš„attention](https://arxiv.org/abs/2112.05682)å’Œ[flash attention](https://arxiv.org/abs/2205.14135)ã€‚

åœ¨å®‰è£…[`optimum`](https://github.com/huggingface/optimum)åŒ…åï¼Œå¯ä»¥æ›¿æ¢ç›¸å…³çš„å†…éƒ¨æ¨¡å—ä»¥ä½¿ç”¨PyTorchçš„åŸç”Ÿattentionï¼š

```python
model = model.to_bettertransformer()
```

ä¸€æ—¦è½¬æ¢å®Œæˆï¼Œè¯·åƒå¾€å¸¸ä¸€æ ·è®­ç»ƒæ¨¡å‹ã€‚

<Tip warning={true}>

PyTorchåŸç”Ÿçš„`scaled_dot_product_attention`æ“ä½œç¬¦åªèƒ½åœ¨æ²¡æœ‰æä¾›`attention_mask`çš„æƒ…å†µä¸‹è½¬æ¢åˆ°Flash Attentionã€‚

é»˜è®¤æƒ…å†µä¸‹ï¼Œåœ¨è®­ç»ƒæ¨¡å¼ä¸‹ï¼ŒBetterTransformeré›†æˆ**åˆ é™¤äº†å¯¹maskçš„æ”¯æŒï¼Œåªèƒ½ç”¨äºä¸éœ€è¦å¡«å……maskçš„æ‰¹å¤„ç†è®­ç»ƒ**ã€‚ä¾‹å¦‚ï¼Œåœ¨æ©ç è¯­è¨€å»ºæ¨¡æˆ–å› æœè¯­è¨€å»ºæ¨¡æœŸé—´ã€‚BetterTransformerä¸é€‚ç”¨äºéœ€è¦å¡«å……maskçš„ä»»åŠ¡çš„å¾®è°ƒæ¨¡å‹ã€‚

</Tip>

æ£€æŸ¥è¿™ä¸ª[åšå®¢å¸–å­](https://pytorch.org/blog/out-of-the-box-acceleration/)ï¼Œäº†è§£æ›´å¤šå…³äºä½¿ç”¨SDPAè¿›è¡ŒåŠ é€Ÿå’ŒèŠ‚çœå†…å­˜çš„ä¿¡æ¯ã€‚